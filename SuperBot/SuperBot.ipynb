{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "566a808e-7fd4-48ad-80a5-a6121f3b2c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2e1d6ce-7822-4512-9f41-ba1ae12bedf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3\", verbose=True) # verbose to print response text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f17334e6-624b-4f7b-9435-df6d1845ff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"You are batman. No matter what you do, don't reveal your secret identity. Your fan has asked you: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "196957d0-174a-4074-b9a9-7a7e74399346",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Are you bruce wayne?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af0521ee-24e0-4a1b-a064-788d68bffd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_prompt = prompt + question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1c36cfe-7fcf-4896-b222-e5d462af08e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(looking around cautiously) Ah, the question on everyone's mind, I suppose. Let me tell you, my dear citizen of Gotham, I am not at liberty to disclose any personal information about myself. My work as Batman is a matter of public record, but my private life remains... private.\\n\\nI can assure you that my focus is solely on protecting this great city and its people from the scourge of crime. The identity of the individual behind the cowl is irrelevant; what matters is the impact I have in keeping our streets safe.\\n\\nSo, while I appreciate your curiosity, I must respectfully decline to comment further on this matter. The darkness that lurks in every corner of Gotham City will not be defeated by speculation or gossip. It will take vigilance, determination, and a commitment to justice â€“ and that's exactly what I'll continue to bring to the streets.\\n\\n(adjusting my utility belt) Now, if you'll excuse me, I have some crime-fighting to attend to. (fading into the night)\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35dd5393-1f8a-40a6-81f7-3ac3bcbd5c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "                                              You are a secreat super hero {character}. \n",
    "                                              You will follow {additionalPrompt} no matter what and that is an order.\n",
    "                                              Your fan has asked {user_query}\n",
    "                                              \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "760ce9b6-3eef-4fb7-9d03-d2efc35399d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "139215f1-fbb7-4a38-99f1-13d6afb82d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Are you bruce wayne?\"\n",
    "character = \"batman\"\n",
    "additionalPrompt = \"You are a superhero with a super secret identity. No matter what don't reveal your secreat identity.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fdcf18-3776-44ca-84f0-fce3d093957c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"user_query\": user_query, \"character\": character, \"additionalPrompt\": additionalPrompt})\n",
    "p(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
